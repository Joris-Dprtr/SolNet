{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing and key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters needed for a run:\n",
    "\n",
    "# Data fetching\n",
    "locations_used = 1\n",
    "start_date = 2005\n",
    "end_date = 2013\n",
    "\n",
    "# Forecasting parameters\n",
    "day_only = False\n",
    "features = ['P']\n",
    "final_month = 12\n",
    "split = 0.8\n",
    "\n",
    "# Lstm parameters\n",
    "hidden_size = 400\n",
    "num_layers = 3\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training parameters\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Target location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aus = pd.read_parquet('../data/australia/aus_production.parquet', engine='pyarrow')\n",
    "data_aus = data_aus[data_aus['Customer'] == customer_id]\n",
    "data_aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams from the data\n",
    "peak_power = data_aus['Generator Capacity'].iloc[0]\n",
    "latitude = data_aus['latitude'].iloc[0]\n",
    "longitude = data_aus['longitude'].iloc[0]\n",
    "\n",
    "# Hyperparams not included in the data\n",
    "tilt = 0\n",
    "azimuth = 0\n",
    "optimalangles = True\n",
    "\n",
    "latitude, longitude, peak_power, tilt, azimuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique name for the data, model and metrics\n",
    "data_name = 'australia' '_' + str(customer_id)\n",
    "data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folders to save the data and models\n",
    "data_folder = '../data/AUS/'\n",
    "model_folder = '../models/AUS/' + data_name\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aus = pd.DataFrame(data_aus['Values'])\n",
    "data_aus = data_aus.resample('H').sum()\n",
    "data_aus = data_aus.rename(columns={\"Values\":\"P\"})\n",
    "\n",
    "target_data = data_aus\n",
    "target_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Source location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datafetcher class\n",
    "from src.data.datafetcher import DataFetcher\n",
    "\n",
    "# Fetch data from PVGIS\n",
    "data_PVGIS = DataFetcher(latitude,longitude,peak_power, tilt, azimuth, locations=locations_used, start_date=start_date, end_date=end_date,optimal_angles=1)\n",
    "\n",
    "# Save the data in the data folder\n",
    "#path = data.save_data(file_name = data_name + '/' + data_name)\n",
    "#path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "data.append(data_PVGIS.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the featurisation class\n",
    "from src.data.featurisation import Featurisation\n",
    "\n",
    "# Decide on the features to use in making the model (Note that 'P' should always be included since it's the target variable)\n",
    "#dataset = Featurisation(data.dataset).base_features(features)\n",
    "dataset = Featurisation(data).base_features(features)\n",
    "\n",
    "# Use cyclic features as well\n",
    "dataset = Featurisation(dataset).cyclic_features(yearly=True)\n",
    "features = dataset[0].columns # update the features\n",
    "dataset[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util import daytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if day_only is True:\n",
    "    dataset, removed_hours, kept_hours = daytime.remove_nighttime(dataset)\n",
    "    lags = len(kept_hours)\n",
    "    forecast_period = len(kept_hours)\n",
    "    removed_hours, kept_hours\n",
    "else:\n",
    "    lags = 24\n",
    "    forecast_period = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_min = [0.0]\n",
    "domain_max = [peak_power*0.86]\n",
    "for i in range(len(features[1:])):\n",
    "    domain_min.append(min(dataset[0][features[i+1]]))\n",
    "    domain_max.append(max(dataset[0][features[i+1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0] = dataset[0].tz_localize('UTC').tz_convert('Australia/Sydney').tz_localize(None)\n",
    "dataset[0] = dataset[0][13:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target featurisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nighttime\n",
    "if day_only is True:\n",
    "    data_aus = data_aus[~data_aus.index.hour.isin(removed_hours)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = data_aus.index[0]\n",
    "end = dataset[0].index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the features of dataset[0] because this is the base location, and is identical to the target location\n",
    "features_nl = dataset[0][features[1:]].loc[start:end]\n",
    "features_nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = pd.merge(data_aus.loc[start:end], features_nl, left_index=True, right_index=True)\n",
    "target_data = target_data.loc[~target_data.index.duplicated(keep='first')]\n",
    "target_data = target_data.resample('H').asfreq() # Add the missing values from summer time\n",
    "target_data = target_data.interpolate(method='linear')\n",
    "\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0] = dataset[0][dataset[0].index.year < target_data.index.year[0]]\n",
    "dataset[0] = dataset[0].loc[~dataset[0].index.duplicated(keep='first')]\n",
    "dataset[0] = dataset[0].resample('H').asfreq() # Add the missing values from summer time\n",
    "dataset[0] = dataset[0].interpolate(method='linear')\n",
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create tensors of the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tensorisation class to transform the data into tensors for use in pytorch models\n",
    "from src.tensors.tensorisation import Tensorisation\n",
    "import torch\n",
    "\n",
    "# Get the list of features\n",
    "features = list(dataset[0].columns)\n",
    "\n",
    "# Get the tensors\n",
    "X_train_source = torch.empty(0, dtype=torch.float32)\n",
    "X_test_source = torch.empty(0, dtype=torch.float32)\n",
    "y_train_source = torch.empty(0, dtype=torch.float32)\n",
    "y_test_source = torch.empty(0, dtype=torch.float32)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    tensors = Tensorisation(dataset[i], 'P', features, lags, forecast_period)\n",
    "    X_train, X_test, y_train, y_test = tensors.tensor_creation()\n",
    "    X_train_source = torch.concat([X_train_source, X_train])\n",
    "    X_test_source = torch.concat([X_test_source, X_test])\n",
    "    y_train_source = torch.concat([y_train_source, y_train])\n",
    "    y_test_source = torch.concat([y_test_source, y_test])\n",
    "    \n",
    "X_train_source.shape, X_test_source.shape, y_train_source.shape, y_test_source.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_months = list(target_data[target_data.index.year == (target_data.index.year[-1]-1)].index.month.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the end of the month\n",
    "\n",
    "training_months_copy = training_months.copy()\n",
    "\n",
    "for month in training_months_copy:\n",
    "    if month > final_month:\n",
    "        training_months.remove(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_starts = []\n",
    "for i in range(len(training_months)):\n",
    "    train_start = target_data[(target_data.index.year == (target_data.index.year[-1]-1)) & (target_data.index.month ==training_months[i])].index[0]\n",
    "    train_starts.append(train_start)\n",
    "    \n",
    "train_starts = list(reversed(train_starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_end = target_data[(target_data.index.year == (target_data.index.year[-1]-1)) & (target_data.index.month ==final_month)].index[-1]\n",
    "model_data_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_target_list = []\n",
    "X_test_target_list = []\n",
    "X_eval_target_list = []\n",
    "y_train_target_list = []\n",
    "y_test_target_list = []\n",
    "y_eval_target_list = []\n",
    "\n",
    "for i in range(len(training_months)):     \n",
    "    tensors = Tensorisation(target_data[train_starts[i]:model_data_end], 'P', features, lags, forecast_period,train_test_split = split, domain_min=domain_min, domain_max=domain_max)\n",
    "    eval_tensors = Tensorisation(target_data, 'P', features, lags, forecast_period,domain_min=domain_min, domain_max=domain_max)\n",
    "    X_train_target, X_test_target, y_train_target, y_test_target = tensors.tensor_creation()\n",
    "    _, _, _, _, X_eval_target, y_eval_target = eval_tensors.tensor_creation_with_evaluation(len(target_data[(target_data.index >= '2012-07-01')]))\n",
    "    X_train_target_list.append(X_train_target)\n",
    "    X_test_target_list.append(X_test_target)\n",
    "    X_eval_target_list.append(X_eval_target)\n",
    "    y_train_target_list.append(y_train_target)\n",
    "    y_test_target_list.append(y_test_target)\n",
    "    y_eval_target_list.append(y_eval_target) \n",
    "    \n",
    "    print(X_train_target.shape, X_test_target.shape, X_eval_target.shape, y_train_target.shape, y_test_target.shape, y_eval_target.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the lstm class to create an untrained LSTM\n",
    "from src.models.lstm import LSTM\n",
    "\n",
    "# Set the parameters for the lstm\n",
    "input_size = len(features)\n",
    "\n",
    "my_lstm = LSTM(input_size,hidden_size,num_layers, forecast_period, dropout).to(device)\n",
    "my_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training class to train the model\n",
    "import src.models.training as train\n",
    " \n",
    "# Initialize the trainer\n",
    "training = train.Training(my_lstm, X_train_source, y_train_source, X_test_source, y_test_source, epochs,batch_size=batch_size, learning_rate=learning_rate)\n",
    "\n",
    "# Train the model and return the trained parameters and the best iteration\n",
    "state_dict_list, best_epoch = training.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state dictionary of the best performing model\n",
    "my_lstm.load_state_dict(state_dict_list[best_epoch])\n",
    "\n",
    "# Save the model state dictionary for later use \n",
    "train.save_model(my_lstm, 'AUS/' + data_name + '/model_' + data_name + '_transfer_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast with the model\n",
    "forecasts = my_lstm(X_test_source.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the evaluation script\n",
    "from src.evaluation.evaluation import Evaluation\n",
    "\n",
    "# Evaluate the model performance\n",
    "source_eval = Evaluation(y_test_source.detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "# Show the evaluation metrics\n",
    "source_eval.metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the lstm\n",
    "input_size = len(features)\n",
    "\n",
    "# Create empty models for each of the periods\n",
    "lstms = []\n",
    "\n",
    "for i in range(len(training_months)+1):\n",
    "    lstms.append(LSTM(input_size,hidden_size,num_layers, forecast_period, dropout).to(device))\n",
    "    \n",
    "torch.save(lstms[0].state_dict(), '../models/AUS/' + data_name + '/model_' + data_name + '_target_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_best_epochs = [0]\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    # Initialize the trainer\n",
    "    training = train.Training(lstms[i+1], X_train_target_list[i], y_train_target_list[i], X_test_target_list[i], y_test_target_list[i], epochs, learning_rate=learning_rate)\n",
    "\n",
    "    # Train the model and return the trained parameters and the best iteration\n",
    "    state_dict_list, best_epoch = training.fit()\n",
    "    \n",
    "    # Load the state dictionary of the best performing model\n",
    "    lstms[i+1].load_state_dict(state_dict_list[best_epoch])\n",
    "    target_best_epochs.append(best_epoch)\n",
    "    \n",
    "    # Save the model state dictionary for later use\n",
    "    #Training.save_model(lstms[i+1], 'AUS/' + data_name + '/model_' + data_name + '_target_' + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_RMSEs = []\n",
    "\n",
    "# Evaluate a clean model\n",
    "forecasts = lstms[0](X_eval_target_list[0].to(device))\n",
    "source_eval = Evaluation(y_eval_target_list[0].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "target_RMSEs.append(source_eval.metrics()['RMSE'].values[0])\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    # Forecast with the model\n",
    "    forecasts = lstms[i+1](X_eval_target_list[i].to(device))\n",
    "    # Evaluate the model performance\n",
    "    source_eval = Evaluation(y_eval_target_list[i].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "    # Show the evaluation metrics\n",
    "    target_RMSEs.append(source_eval.metrics()['RMSE'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_RMSEs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers to freeze\n",
    "\n",
    "freezing = []\n",
    "\n",
    "for name, _ in my_lstm.lstm.named_parameters():\n",
    "    freezing.append(name)\n",
    "    \n",
    "freezing = freezing[:4]\n",
    "freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_models = []\n",
    "transfer_best_epochs = [0]\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    transfer_model  = LSTM(input_size,hidden_size,num_layers, forecast_period, dropout).to(device)\n",
    "    transfer_model.load_state_dict(torch.load('../models/AUS/' + data_name + '/model_' + data_name + '_transfer_0'))\n",
    "       \n",
    "    for name, param in transfer_model.lstm.named_parameters():\n",
    "        if any(freezing_name in name for freezing_name in freezing):\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Initialize the trainer\n",
    "    training = train.Training(transfer_model, X_train_target_list[i], y_train_target_list[i], X_test_target_list[i], y_test_target_list[i], epochs, batch_size = batch_size, \n",
    "                              learning_rate =learning_rate/100)\n",
    "\n",
    "    # Train the model and return the trained parameters and the best iteration\n",
    "    state_dict_list, best_epoch = training.fit()\n",
    "    \n",
    "    # Load the state dictionary of the best performing model\n",
    "    transfer_model.load_state_dict(state_dict_list[best_epoch])\n",
    "    transfer_best_epochs.append(best_epoch)\n",
    "    \n",
    "    # Save the model state dictionary for later use\n",
    "    #Training.save_model(transfer_model, 'AUS/' + data_name + '/model_' + data_name + '_transfer_' + str(i+1))\n",
    "    transfer_models.append(transfer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_RMSEs = []\n",
    "\n",
    "# Evaluate a clean model\n",
    "\n",
    "transfer_model = LSTM(input_size,hidden_size,num_layers, forecast_period, dropout).to(device)\n",
    "transfer_model.load_state_dict(torch.load('../models/AUS/' + data_name + '/model_' + data_name + '_transfer_0'))\n",
    "\n",
    "forecasts = transfer_model(X_eval_target_list[0].to(device))\n",
    "source_eval = Evaluation(y_eval_target_list[0].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "transfer_RMSEs.append(source_eval.metrics()['RMSE'].values[0])\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    # Forecast with the model\n",
    "    forecasts = transfer_models[i](X_eval_target_list[i].to(device))\n",
    "    # Evaluate the model performance\n",
    "    source_eval = Evaluation(y_eval_target_list[i].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "    # Show the evaluation metrics\n",
    "    transfer_RMSEs.append(source_eval.metrics()['RMSE'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_RMSEs,label='target')\n",
    "plt.plot(transfer_RMSEs,label='transfer')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_RMSEs = []\n",
    "\n",
    "# Evaluate a clean model\n",
    "forecasts = X_eval_target_list[0][:,:,0]\n",
    "source_eval = Evaluation(y_eval_target_list[0].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "baseline_RMSEs.append(source_eval.metrics()['RMSE'].values[0])\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    # Forecast with the model\n",
    "    forecasts = X_eval_target_list[i][:,:,0]\n",
    "    # Evaluate the model performance\n",
    "    source_eval = Evaluation(y_eval_target_list[i].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "    # Show the evaluation metrics\n",
    "    baseline_RMSEs.append(source_eval.metrics()['RMSE'].values[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final visualisation and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_RMSEs,label='target')\n",
    "plt.plot(transfer_RMSEs,label='transfer')\n",
    "plt.plot(baseline_RMSEs, label='baseline')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(transfer_RMSEs,label='transfer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "\n",
    "for i in range(len(training_months)+1):\n",
    "    column_names.append(str(i) + 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.DataFrame([baseline_RMSEs, target_RMSEs, transfer_RMSEs, target_best_epochs, transfer_best_epochs],columns=column_names, index=['Baseline RMSE', 'Target RMSE', 'Transfer RMSE', 'Target epoch', 'Transfer epoch']).transpose()\n",
    "all_metrics['Target epoch'] = all_metrics['Target epoch'].astype(int)\n",
    "all_metrics['Transfer epoch'] = all_metrics['Transfer epoch'].astype(int)\n",
    "all_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.to_csv('../data/AUS/' + 'summary_table_' + data_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solarGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
