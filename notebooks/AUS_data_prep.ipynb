{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AUS dataprep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook transforms the data as given by Ausgrid in a format that we can use with our models, and adds (approximate) latitude and longitude information for all the zipcodes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus_2012 = pd.read_csv('../data/australia/2011-2012 Solar home electricity data v2.csv')\n",
    "aus_2013 = pd.read_csv('../data/australia/2012-2013 Solar home electricity data v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aus_clean(aus_raw):\n",
    "    \"\"\"\n",
    "    Transform the Ausgrid data in a pandas dataframe which can be used in our code\n",
    "    :param aus_raw: the data in the original format, as presented in a pandas DataFrame by simply doing pd.read_csv(file) \n",
    "    :return: a new pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Only keep GG for solar generation\n",
    "    # Filter the DataFrame to keep only rows with 'GG' in the 'Consumption Category' column\n",
    "    aus_df = aus_raw[aus_raw['Consumption Category'] == 'GG']\n",
    "    \n",
    "    # Extract the time columns\n",
    "    time_columns = aus_df.columns[5:-1]\n",
    "    \n",
    "    # Melt the DataFrame to combine the half-hour columns into rows under the \"Values\" column\n",
    "    aus_melted = pd.melt(aus_df, id_vars=['date', 'Customer', 'Postcode', 'Generator Capacity'], value_vars=time_columns, var_name='Time', value_name='Values')\n",
    "    \n",
    "    # Correctly set the date in the right format, as our index\n",
    "    aus_melted['date'] = aus_melted['date'] + ' ' + aus_melted['Time'] + ':00'\n",
    "    aus_melted.drop(columns=['Time'], inplace=True)\n",
    "    aus_melted.set_index('date', inplace=True)\n",
    "    aus_melted.index = pd.to_datetime(aus_melted.index, format=\"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "    # Sort the DataFrame by the datetime index and the customer\n",
    "    aus_melted.sort_values(by=['Customer', 'date'], inplace=True)\n",
    "    \n",
    "    return aus_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the 2012 data\n",
    "aus_2012_clean = aus_clean(aus_2012)\n",
    "aus_2012_clean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the 2013 data\n",
    "aus_2013_clean = aus_clean(aus_2013)\n",
    "aus_2013_clean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Concatenate the two dataframes and sort the values\n",
    "aus_combined = pd.concat([aus_2012_clean,aus_2013_clean], axis=0)\n",
    "aus_combined.sort_values(by=['Customer', 'date'], inplace=True)\n",
    "\n",
    "aus_combined"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get unique customer IDs\n",
    "customer_ids = aus_combined['Customer'].unique()\n",
    "\n",
    "# Find missing dates for each customer\n",
    "missing_dates = {}\n",
    "for customer_id in customer_ids:\n",
    "    customer_data = aus_combined[aus_combined['Customer'] == customer_id]\n",
    "    date_range = pd.date_range(start='2011-07-01', end='2013-07-01', freq='30T')\n",
    "    date_range = date_range[:-1]\n",
    "    missing_dates[customer_id] = date_range[~date_range.isin(customer_data.index)]\n",
    "    \n",
    "missing_dates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the missing dates\n",
    "plt.plot(aus_combined[aus_combined['Customer'] == 2]['Values'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove customer 2 from the final DataFrame\n",
    "aus_combined = aus_combined[aus_combined['Customer'] != 2.0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load our lat/long data for the zipcodes\n",
    "with open(\"../data/australia/location_dict.json\", 'r') as file:\n",
    "    location_dict = json.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "location_dict['2076']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform the Postcode column into strings to fit the dictionary\n",
    "aus_combined['Postcode'] = aus_combined['Postcode'].astype(int).astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use the map function to create 'latitude' and 'longitude' columns\n",
    "aus_combined['latitude'] = aus_combined['Postcode'].map({postcode: data['latitude'] for postcode, data in location_dict.items()})\n",
    "aus_combined['longitude'] = aus_combined['Postcode'].map({postcode: data['longitude'] for postcode, data in location_dict.items()})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aus_combined"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a parquet file\n",
    "aus_combined.to_parquet('../data/australia/aus_production.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SolNet_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
